{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Streams sample application\n",
    "\n",
    "This sample demonstrates creating a Streams Python application to perform some analytics, and viewing the results.\n",
    "\n",
    "Familiarity with [Python](https://www.python.org/about/gettingstarted/) is recommended.\n",
    "\n",
    "\n",
    "In this notebook, you'll see examples of how to :\n",
    " 1. [Setup a connection to the Streams instance](#setup)\n",
    " 2. [Create the application](#create)\n",
    " 3. [Submit the application](#launch)\n",
    " 4. [Connect to the running application to view data](#view)\n",
    " 5. [Stop the application](#cancel)\n",
    "\n",
    "# Overview\n",
    "\n",
    "**About the sample**\n",
    "\n",
    "This application simulates a data hub that receives readings from sensors. It computes the 30 second rolling average of the reported readings using [Pandas](https://pandas.pydata.org/).  \n",
    "\n",
    "**How it works**\n",
    "   \n",
    "A Streams Python application processes a continuous and potentially infinite stream of data. The data is processed in memory and is not stored in a database first.\n",
    "\n",
    "The Python application created in this notebook is submitted to the IBM Streams service for execution. Once the application is running in the service, you can connect to it from the notebook to continuously retrieve the results.\n",
    "\n",
    "<img src=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/04/how-it-works.jpg\" alt=\"How it works\">\n",
    "\n",
    "\n",
    "### Documentation\n",
    "\n",
    "- [Streams Python development guide](https://ibmstreams.github.io/streamsx.documentation/docs/latest/python/)\n",
    "- [Streams Python API](https://streamsxtopology.readthedocs.io/)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prerequisites\n",
    "\n",
    "This notebook can be used as-is from within an IBM Cloud Pak for Data project. \n",
    "\n",
    "<a name=\"setup\"></a>\n",
    "\n",
    "# 1. Set up a connection to the Streams instance\n",
    "\n",
    "\n",
    "To submit the application for execution, you have to connect to the Streams instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cpd\"></a>\n",
    "### 1.1 Connect to a Streams instance from an IBM Cloud Pak for Data  project\n",
    "\n",
    "In order to submit a Streams application you need to provide the name of the Streams instance.\n",
    "\n",
    "1. From the navigation menu, click **My instances**.\n",
    "2. Click the **Provisioned Instances** tab.\n",
    "3. Update the value of `streams_instance_name` in the cell below according to your Streams instance name\n",
    "4. Run the cell and skip to section 1.2\n",
    "\n",
    "The cell below defines a function called `submit_topology` that will be used later on to submit the `Topology` once it is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a Streams instance from an IBM Cloud Pak for Data project\n",
    "\n",
    "from icpd_core import icpd_util\n",
    "from streamsx.topology import context\n",
    "\n",
    "streams_instance_name = \"streams\" ## Change this to Streams instance\n",
    "cfg=icpd_util.get_service_instance_details(name=streams_instance_name)\n",
    "\n",
    "def submit_topology(topo):\n",
    "    global cfg\n",
    "    # Disable SSL certificate verification if necessary\n",
    "    cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "    # Topology wil be deployed as a distributed app\n",
    "    contextType = context.ContextTypes.DISTRIBUTED\n",
    "    return context.submit (contextType, topo, config = cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Verify `streamsx` package version\n",
    "\n",
    "Run the cell below to check which version of the `streamsx` package is installed.  \n",
    "\n",
    "If you need to upgrade, use\n",
    "\n",
    "- `import sys`\n",
    "- `!{sys.executable} -m pip install --user --upgrade streamsx` to upgrade the package.\n",
    "- Or, use  `!{sys.executable} -m pip install --user streamsx==somever` to install a specific version of the package. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: streamsx package version: 1.14.13\n"
     ]
    }
   ],
   "source": [
    "# Verify streamsx package version\n",
    "\n",
    "import streamsx.topology.context\n",
    "print(\"INFO: streamsx package version: \" + streamsx.topology.context.__version__)\n",
    "\n",
    "#For more details uncomment line below.\n",
    "#!pip show streamsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create\"></a>\n",
    "# 2. Create the application\n",
    " \n",
    "\n",
    "All Streams applications start with  a `Topology` object, so start by creating one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsx.topology.topology import Topology\n",
    "\n",
    "topo = Topology(name=\"Cart Item Cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define sources\n",
    "Your application needs some data to analyze, so the first step is to define a data source that produces the data to be analyzed. \n",
    "\n",
    "Next, use the data source to create a `Stream` object. A `Stream` is a potentially infinite sequence of tuples containing the data to be analyzed.\n",
    "\n",
    "Tuples are Python objects by default. Other supported formats include JSON. [See the doc for all supported formats](https://streamsxtopology.readthedocs.io/en/stable/streamsx.topology.topology.html#stream)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Define a source class\n",
    "\n",
    "Define a callable class that will produce the data to be analyzed.\n",
    "\n",
    "This example class simulates readings from a clickstream. Each reading is a Python `dict` containing the customer click data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2  Create the `Stream `\n",
    "\n",
    "Create a `Stream` called  `clicks` that will contain the simulated data that `ClickStreamReader` produces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'etc/clickstream.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add our clickstream csv file to the topology so that our application can uss it\n",
    "# \"/ect\" is where we will store the data on the IBM Streams service cluster\n",
    "# Change the filename if needed\n",
    "\n",
    "topo.add_file_dependency('/project_data/data_asset/clickstream.csv', 'etc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that can read/process our csv file\n",
    "\n",
    "import csv\n",
    "from streamsx.ec import get_application_directory\n",
    "\n",
    "# a class which can be used in topology as a source\n",
    "class CSVFileReader:\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "    def __call__(self):\n",
    "        # Convert each row in the file to a dict\n",
    "        click_file =  os.path.join(get_application_directory(), \"etc\", self.file_name)\n",
    "        col_names = [\"customer_id\", \"time_stamp\", \"click_event_type\", \"product_name\", \"product_category\", \"product_price\",\n",
    "                     \"total_price_of_basket\", \"total_number_of_items_in_basket\", \"total_number_of_distinct_items_in_basket\", \"session_duration\"]\n",
    "       \n",
    "        # run this indefinitely so that there will always be data for the view\n",
    "        while True:\n",
    "            with open(click_file) as handle:\n",
    "                reader = csv.DictReader(handle, delimiter=',',\n",
    "                                                fieldnames=col_names)\n",
    "                #yield the lines in the file one at a time\n",
    "                for row in reader:\n",
    "                    yield dict(customerId = row[\"customer_id\"],\n",
    "                               timeStamp = row[\"time_stamp\"], \n",
    "                               clickEventType = row[\"click_event_type\"],\n",
    "                               productName = row[\"product_name\"],\n",
    "                               productCategory = row[\"product_category\"],\n",
    "                               productPrice = float(row[\"product_price\"]),\n",
    "                               totalPriceOfBasket = float(row[\"total_price_of_basket\"]),\n",
    "                               totalNumberOfItemsInBasket = int(row[\"total_number_of_items_in_basket\"]),\n",
    "                               totalNumberOfDistinctItemsInBasket = int(row[\"total_number_of_distinct_items_in_basket\"]),\n",
    "                               sessionDuration = row[\"session_duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the source of our application. \n",
    "# The stream data will be each row of our csv file\n",
    "\n",
    "# Change the filename if needed\n",
    "clicks = topo.source(CSVFileReader(\"clickstream.csv\"))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Analyze data\n",
    "\n",
    "Use a variety of methods in the `Stream` class to analyze your in-flight data, including applying machine learning models.\n",
    " \n",
    "This section will:\n",
    "- Filter out tuples based on a condition,\n",
    "- Compute the total cost in the customers cart.\n",
    "\n",
    "Built-in methods exist for common operations, such as <code>Stream.filter</code> and <code>Stream.split</code>, which filter or split a stream of data respectively.\n",
    "\n",
    "See the <a href=\"/streamsx.documentation/docs/python/1.6/python-appapi-devguide-4/\"> common operations section</a> for other common examples. Check out the <a href=\"https://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.topology.topology.html#streamsx.topology.topology.Stream\">documentation </a> of the <code>Stream</code> class for full list of functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Filter data from the  `Stream`  \n",
    "\n",
    "Use `Stream.filter()` to remove data that doesn't match a certain condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept only clicks that add items to a cart\n",
    "\n",
    "cart_items = clicks.filter(lambda x : x[\"clickEventType\"] == \"add_to_cart\",\n",
    "                           name=\"CartItems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add up cost of items in cart\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def total_cost(items_in_window):\n",
    "    # grab all the clicks in the stream window\n",
    "    df = pd.DataFrame(items_in_window)\n",
    "    \n",
    "    # sort by customer ID\n",
    "    clicks_by_id = df.groupby(\"customerId\")\n",
    "     \n",
    "    # get the total amount per customer\n",
    "    totals = clicks_by_id[\"productPrice\"].sum()\n",
    "    \n",
    "    result = []\n",
    "    for id, tot in totals.iteritems():\n",
    "        result.append({\"customer_id\": id,\n",
    "                       \"total\": round(tot,2)})\n",
    "               \n",
    "    return result\n",
    "\n",
    "# set our window size and process all \"add to cart\" clicks in that window\n",
    "interval = timedelta(seconds=30)\n",
    "window = cart_items.last(size=interval).trigger(when=timedelta(seconds=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_total = window.aggregate(total_cost).flat_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Create a `View` to preview the tuples on the `Stream` \n",
    "\n",
    "\n",
    "A `View` is a connection to a `Stream` that becomes activated when the application is running. The connection allows you to access the data on the `Stream` as it is being processed.\n",
    "\n",
    "\n",
    "After submitting the `Topology`, we use a `View`  to examine the from within the notebook [in section 4](#view).\n",
    "\n",
    "To view the data on the `running_total Stream`, define a `View` using `Stream.view()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_view = running_total.view(name=\"RunningTotal\", \n",
    "                      description=\"Sample of cart content prices per customer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can <a href=\"http://ibmstreams.github.io/streamsx.documentation/docs/python/1.6/python-appapi-devguide-6/#accessing-the-tuples-of-a-view\">connect to a view in <em>any</em> running Streams job using the REST API</a> , regardless of what language was used to create the application.\n",
    "\n",
    "# 2.4 Define output\n",
    "\n",
    "You could also enable a microservices based architecture by publishing the results so that other Streams applications can connect to it.\n",
    "\n",
    "Use `Stream.publish()` to make the `running_total Stream` available to other applications. \n",
    "\n",
    "To send the stream to another database or system, use a sink function (similar to the source function) and invoke it using `Stream.for_each`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<streamsx.topology.topology.Sink at 0x7f855c1eff60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# publish results as JSON\n",
    "running_total.publish(topic=\"TotalsReadings\",\n",
    "                      schema=json, \n",
    "                      name=\"PublishTotals\")\n",
    "\n",
    "# Other options include:\n",
    "# invoke another sink function:\n",
    "# running_total.for_each(func=send_to_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"launch\"></a>\n",
    "\n",
    "# 3. Submit the application\n",
    "A running Streams application is called a *job*. Use this cell to submit the `Topology` for execution, using the `submit_topology` function [defined in step 1](#setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting Topology to Streams for execution..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612be50e90f0481f868e048ba9a3993f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='info', description='Initializing', max=10, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insecure host connections enabled.\n",
      "Insecure host connections enabled.\n",
      "Insecure host connections enabled.\n",
      "/user-home/_global_/python-3/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobId:  32 \n",
      "Job name:  ibmstreamswithnotebook::CartItemCost_32\n"
     ]
    }
   ],
   "source": [
    "# The submission_result object contains information about the running application, or job\n",
    "print(\"Submitting Topology to Streams for execution..\")\n",
    "submission_result = submit_topology(topo)\n",
    "\n",
    "if submission_result.job:\n",
    "  streams_job = submission_result.job\n",
    "  print (\"JobId: \", streams_job.id , \"\\nJob name: \", streams_job.name)\n",
    "else:\n",
    "  print(\"Submission failed: \"   + str(submission_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"view\"></a>\n",
    "\n",
    "# 4. Use a `View` to access data from the job\n",
    "\n",
    "Now that the job is started, use the `my_view` object you created in step 2.3 to start retrieving data from the `running_total Stream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching view data ...\n",
      "{'customer_id': '10002', 'total': 2434.85}\n",
      "{'customer_id': '10004', 'total': 863.28}\n",
      "{'customer_id': '10018', 'total': 2775.21}\n",
      "{'customer_id': '10022', 'total': 2199.57}\n",
      "{'customer_id': '10044', 'total': 575.28}\n",
      "{'customer_id': '10049', 'total': 323.28}\n",
      "{'customer_id': '10051', 'total': 107.64}\n",
      "{'customer_id': '10053', 'total': 3025.23}\n",
      "{'customer_id': '10055', 'total': 466.56}\n",
      "{'customer_id': '10059', 'total': 35.64}\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching view data ...\")\n",
    "# Connect to the view and display the data\n",
    "queue = my_view.start_data_fetch()\n",
    "try:\n",
    "    for val in range(10):\n",
    "        print(queue.get())    \n",
    "finally:\n",
    "    my_view.stop_data_fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Display the results in real time\n",
    "Calling `View.display()` from the notebook displays the results of the view in a table that is updated in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2160785ff2b44f4882929ad1dba75096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='Sample of cart content prices per customer', description='RunningTot…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the results in real-time for 30 seconds\n",
    "my_view.display(duration=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 See job status \n",
    "\n",
    "In IBM Cloud Pak for Data, you can view job status and logs with the Job Graph.\n",
    "\n",
    "To view job status and logs:\n",
    "<ol>\n",
    "<li>From the main menu, go to <b>My Instances &gt; Jobs</b>. </li>\n",
    "<li>Find your job based on the <code>JobId</code> printed when you submitted the topology.</li>\n",
    "<li>Select <b>View graph</b> from the context menu action for the running job.</li>\n",
    "</ol>\n",
    "\n",
    "For all other development environments, use the Streams Console.\n",
    "\n",
    "[See instructions and an example](http://ibm.biz/Bdz6yD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cancel\"></a>\n",
    "\n",
    "# 5. Cancel the job\n",
    "Streams jobs run indefinitely, so make sure you cancel the job once you are finished running the sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd3ea8c0569439ab1c01f73e798ae01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='danger', description='Cancel job: ibmstreamswithnotebook::CartItemCost_32'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cancel the job in the IBM Streams service\n",
    "submission_result.cancel_job_button()\n",
    "\n",
    "# You can also interact with the job through the Job object returned from submission_result.job\n",
    "# For example, use job.cancel() to cancel the running job directly.\n",
    "#streams_job.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We started with a `Stream` called `clicks`, which contained the data we wanted to analyze. Next, we used functions in the `Stream` object to perform simple analysis and produced the `running_totals` stream.  This stream is `published` for other applications running within our Streams instance to access.\n",
    "\n",
    "After submitting the application to the Streams service, we used the `my_view` view to see the results.\n",
    "\n",
    "\n",
    "\n",
    "# Learn more \n",
    "\n",
    "- **Find more samples**: This notebook is one of several sample notebooks available in the [starter notebooks repository on GitHub](https://github.com/IBMStreams/sample.starter_notebooks). Visit the repository for examples of how to connect to common data sources, including Apache Kafka, IBM, and Db2 Warehouse. \n",
    "\n",
    "\n",
    "- Learn more about how to use the API from the [development guide](http://ibmstreams.github.io/streamsx.documentation/docs/python/1.6/python-appapi-devguide/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
